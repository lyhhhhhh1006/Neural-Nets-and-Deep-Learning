{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW-4: Text classification with RNN\n",
        "\n",
        "In this assignment we will create a labeled dataset from a corpus of novels. \n",
        "\n",
        "We will then use this data to train recurrent neural networks for text classification.\n",
        "\n",
        "**Software**: You can use pytorch OR Keras, however, Keras is recommended since various relevant examples are included in Chapter-6 of the textbook and in the shared codes folder.\n",
        "\n",
        "**Submission:**\n",
        "* You need to upload ONE document to Canvas when you are done\n",
        "  * (1) A PDF (or HTML) of the completed form of this notebook \n",
        "  * DO NOT UPLOAD THE RAW TEXT DATA, JUST THE COMPLETED NOTEBOOK\n",
        "* The final uploaded version should NOT have any code-errors present \n",
        "* All outputs must be visible in the uploaded version, including code-cell outputs, images, graphs, etc\n",
        "* **Total points:** 41.66\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection\n",
        "\n",
        "* Create a labeled corpus of novels by doing ONE of the following\n",
        "  * Option-1: (title-prediction) Select and download at least 5 novels from project Gutenberg (label=title)\n",
        "  * Option-2: (author-prediction) Select and download at least 5 novels from project Gutenberg with different authors (label=author)\n",
        "  * **Note**: You can also be creative and come up with a different labeling method (e.g. genre)\n",
        "  * **Note**: You can also use the Harry Potter novels (or any other plain-text novels you can find) instead of project Gutenberg \n",
        "    * https://github.com/formcept/whiteboard/tree/master/nbviewer/notebooks/data/harrypotter\n",
        "  * Store the plain-text files in a logical way in a folder \"./data/\" (do not upload for submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HW-4.1.1 Data cleaning and preparation\n",
        "\n",
        "* Write a code to ingest, clean, and break the novels into chunks of text, either sentences or paragraphs (each with the relevant label)\n",
        "  * You can recycle the relevant codes from previous assignments\n",
        "  * You can do this is an different `.ipynb` file if you want, however, make sure to upload it to Canvas if you do! \n",
        "* Convert this into a dataset suitable for RNN analysis, \n",
        "* Vectorize the text: Either by (any option is fine)\n",
        "  * (1) Doing word-embedding with Gensim as a pre-processing step \n",
        "  * (2) using one-hot-encoding  \n",
        "  * (3) By training an embedding layer with Keras as the first layer of your model \n",
        "  * Make sure to retain the sequential nature of the text when you vectorize.\n",
        "  * Feel free to do it differently than the textbook if you prefer\n",
        "* When debugging and proto-typing, donâ€™t use the entire novel (start small and scale up)\n",
        "* The final result should be a saved file with the processed-vectorized data ready for analysis\n",
        "* Document your process using markdown between code cells to help external collaborators understand what you are doing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('data/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HW-4.1.2 Bench-mark-1: Simple-RNN\n",
        "\n",
        "*  Train a Simple-RNN model to predict the novel category labels based on the text\n",
        "*  Try to maximize the validation accuracy by doing manual (or automated) hyper-parameter tuning\n",
        "   *  Do K=1 validation (i.e just one split of training-test-validation)\n",
        "   *  Include some form of regularization (L1, L2, Dropout) \n",
        "   *  Include training history Convergence plots for the validation and training sets \n",
        "   *  report the final training/test/validation accuracy at the end \n",
        "   *  Save your final trained model to a file\n",
        "*  Document your process using markdown between code cells to help external collaborators understand what you are doing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HW-4.1.3 Bench-mark-2: 1D-CNN\n",
        "\n",
        "*  Train a 1D-CNN model to predict the novel category labels based on the text\n",
        "*  Try to maximize the validation accuracy by doing manual (or automated) hyper-parameter tuning\n",
        "   *  Do K=1 validation (i.e just one split of training-test-validation)\n",
        "   *  Include some form of regularization (L1, L2, Dropout) \n",
        "   *  Include training history Convergence plots for the validation and training sets \n",
        "   *  report the final training/test/validation accuracy at the end \n",
        "   *  Save your final trained model to a file\n",
        "*  Document your process using markdown between code cells to help external collaborators understand what you are doing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HW-4.1.4 LSTM or GRU models\n",
        "\n",
        "*  Train an LSTM or GRU model to predict the novel category labels based on the text\n",
        "   *  Try to exceed the accuracy of the baseline models \n",
        "*  Try to maximize the validation accuracy by doing manual (or automated) hyper-parameter tuning\n",
        "   *  Do K=1 validation (i.e just one split of training-test-validation)\n",
        "   *  Include some form of regularization (L1, L2, Dropout) \n",
        "   *  Include training history Convergence plots for the validation and training sets \n",
        "   *  report the final training/test/validation accuracy at the end \n",
        "   *  Save your final trained model to a file\n",
        "*  Document your process using markdown between code cells to help external collaborators understand what you are doing. \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('anly590')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "515f5c6cd1348fb965e5c6b4ded4ef871d1b3a97751352e2d745eb18d53490ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
