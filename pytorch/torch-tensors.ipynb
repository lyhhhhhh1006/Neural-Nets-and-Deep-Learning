{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch basic operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \ttorch \n",
    "import  numpy\tas\tnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE ARRAYS\n",
    "A=np.array([[11., 12, 13], [21,22,23]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "NUMPY EXAMPLE\n",
      "-------------------\n",
      "A:\t\n",
      "[[11. 12. 13.]\n",
      " [21. 22. 23.]]\n",
      "A.T\n",
      "[[11. 21.]\n",
      " [12. 22.]\n",
      " [13. 23.]]\n",
      "A.shape   (2, 3)\n",
      "A[0,0]\t\t 11.0\n",
      "A[:,0]\t\t [11. 21.]\n",
      "A[0,:]\t\t [11. 12. 13.]\n",
      "A[0,1:2]\t\t [12.]\n",
      "A[0,0].item()\t 11.0\n",
      "np.sin(A):\t\t\n",
      "[[-0.99999021 -0.53657292  0.42016704]\n",
      " [ 0.83665564 -0.00885131 -0.8462204 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"NUMPY EXAMPLE\")\n",
    "print(\"-------------------\")\n",
    "print(\"A:\t\")\n",
    "print(A)\n",
    "print(\"A.T\")\n",
    "print(A.T)\n",
    "print(\"A.shape  \",A.shape)\n",
    "print(\"A[0,0]\t\t\",A[0,0])\n",
    "print(\"A[:,0]\t\t\",A[:,0])\n",
    "print(\"A[0,:]\t\t\",A[0,:])\n",
    "print(\"A[0,1:2]\t\t\",A[0,1:2])\n",
    "print(\"A[0,0].item()\t\",A[0,0].item())\n",
    "print(\"np.sin(A):\t\t\")\n",
    "print(np.sin(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE: False\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA AVAILABLE:\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "TORCH TENSOR EXAMPLE\n",
      "-------------------\n",
      "A:\t\n",
      "tensor([[11., 12., 13.],\n",
      "        [21., 22., 23.]], dtype=torch.float64)\n",
      "A.shape   torch.Size([2, 3])\n",
      "A[0,0]\t\t\n",
      "tensor(11., dtype=torch.float64)\n",
      "A[:,0]\t\t\n",
      "tensor([11., 21.], dtype=torch.float64)\n",
      "A[0,:]\t\t\n",
      "tensor([11., 12., 13.], dtype=torch.float64)\n",
      "A[:,-1]\t\t\n",
      "tensor([13., 23.], dtype=torch.float64)\n",
      "A.T\n",
      "tensor([[11., 21.],\n",
      "        [12., 22.],\n",
      "        [13., 23.]], dtype=torch.float64)\n",
      "A[0,0].item()\t 11.0\n",
      "torch.sin(A):\t\t\n",
      "A device cpu\n",
      "A dtype torch.float64\n",
      "A is_contiguous True\n",
      "A.T is_contiguous False\n",
      "A.T is_contiguous True\n",
      "A requires_grad False\n",
      "A requires_grad True\n",
      "A is cuda False\n",
      "A.tolist\t [[11.0, 12.0, 13.0], [21.0, 22.0, 23.0]]\n",
      "A.flatten()\n",
      "tensor([11., 12., 13., 21., 22., 23.], dtype=torch.float64,\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "tensor([[-1.0000, -0.5366,  0.4202],\n",
      "        [ 0.8367, -0.0089, -0.8462]], dtype=torch.float64,\n",
      "       grad_fn=<SinBackward0>)\n",
      "tensor([[-1.0000, -0.5366,  0.4202],\n",
      "        [ 0.8367, -0.0089, -0.8462]], dtype=torch.float64,\n",
      "       grad_fn=<SinBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"TORCH TENSOR EXAMPLE\")\n",
    "print(\"-------------------\")\n",
    "A=torch.tensor(A)\t#CONVERT TO TORCH TENSOR \n",
    "print(\"A:\t\")\n",
    "print(A)\n",
    "print(\"A.shape  \",A.shape)\n",
    "print(\"A[0,0]\t\t\"); print(A[0,0])\n",
    "print(\"A[:,0]\t\t\"); print(A[:,0])\n",
    "print(\"A[0,:]\t\t\"); print(A[0,:])\n",
    "print(\"A[:,-1]\t\t\"); print(A[:,-1])\n",
    "print(\"A.T\")\n",
    "print(A.T)\n",
    "print(\"A[0,0].item()\t\",A[0,0].item())\n",
    "print(\"torch.sin(A):\t\t\")\n",
    "print(\"A device\",A.device)\n",
    "print(\"A dtype\",A.dtype)\n",
    "print(\"A is_contiguous\",A.is_contiguous())\n",
    "AT=A.T\n",
    "print(\"A.T is_contiguous\",AT.is_contiguous())\n",
    "AT=AT.contiguous()\n",
    "print(\"A.T is_contiguous\",AT.is_contiguous())\n",
    "print(\"A requires_grad\",A.requires_grad)\n",
    "A.requires_grad_(requires_grad=True)\n",
    "print(\"A requires_grad\",A.requires_grad)\n",
    "print(\"A is cuda\",A.is_cuda)\n",
    "print(\"A.tolist\t\",A.tolist())\n",
    "print(\"A.flatten()\"); print(A.flatten())\n",
    "print(torch.sin(A))\n",
    "print(A.sin())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "TENSORS VIEWS\n",
      "-------------------\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7]]) True\n",
      "tensor([[[1, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]]) tensor([[[1, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "tensor([[1, 1],\n",
      "        [2, 2],\n",
      "        [3, 3]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"TENSORS VIEWS\")\n",
    "print(\"-------------------\")\n",
    "x=torch.arange(8)\n",
    "print(x)\n",
    "x1=x.view(4, 2)\n",
    "print(x1,x1.view(4, 2).is_contiguous())\n",
    "x1[0]=1  #CHANGES ORIGINAL\n",
    "print(x.view(2, 2, 2),x.view(2,2, 2))\n",
    "print(x.view(2, 2, 2).shape)\n",
    "\n",
    "x = torch.tensor([[1], [2], [3]])\n",
    "print(x,x.size())\n",
    "print(x.expand(3, 4))\n",
    "print(x.expand(3, 2))\n",
    "# -1 means not changing the size of that dimension\n",
    "print(x.expand(-1, 4))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8712, -2.0256, -0.7236],\n",
      "        [ 0.4815, -0.0425,  0.5788],\n",
      "        [ 0.2165, -0.9558,  1.0351]])\n",
      "tensor([0.2165])\n",
      "tensor([ 0.4815, -0.9558])\n",
      "tensor([ 0.8712, -0.0425,  1.0351])\n",
      "tensor([-2.0256,  0.5788])\n",
      "tensor([-0.7236])\n",
      "(tensor([[0.8712],\n",
      "        [0.4815],\n",
      "        [0.2165]]), tensor([[-2.0256],\n",
      "        [-0.0425],\n",
      "        [-0.9558]]), tensor([[-0.7236],\n",
      "        [ 0.5788],\n",
      "        [ 1.0351]]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "print(x)\n",
    "print(torch.diagonal(x,-2))\n",
    "print(torch.diagonal(x,-1))\n",
    "print(torch.diagonal(x, 0))\n",
    "print(torch.diagonal(x, 1))\n",
    "print(torch.diagonal(x, 2))\n",
    "\n",
    "# print(x.split(1, 0))\n",
    "print(x.split(1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "OPERATIONS\n",
      "-------------------\n",
      "torch.Size([2, 3]) torch.Size([1, 3])\n",
      "tensor([[12.5000, 13.5000, 14.5000],\n",
      "        [22.5000, 23.5000, 24.5000]])\n",
      "BROADCASTING: tensor([[22., 24., 26.],\n",
      "        [32., 34., 36.]])\n",
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]])\n",
      "tensor([[1.0000, 1.0000, 1.0000]])\n",
      "tensor([[121., 144., 169.],\n",
      "        [231., 264., 299.]])\n",
      "tensor([[121., 144., 169.],\n",
      "        [441., 484., 529.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"-------------------\")\n",
    "print(\"OPERATIONS\")\n",
    "print(\"-------------------\")\n",
    "A=torch.tensor([[11., 12, 13], [21,22,23]]);\n",
    "B=torch.tensor([[11., 12, 13]]);\n",
    "print(A.shape,B.shape)\n",
    "print(A+1.5)\n",
    "print(\"BROADCASTING:\",A+B)\n",
    "print(torch.sigmoid(A))\n",
    "print(B.sigmoid())\n",
    "print(A*B)\n",
    "print(A**2.0)\n",
    "print(A.tanh())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "COMPUTE GRADIENT-1\n",
      "-------------------\n",
      "AUTOGRAD:\n",
      " tensor([[ 6., 24.],\n",
      "        [54., 96.]])\n",
      "EXPECTED:\n",
      " tensor([[ 6., 24.],\n",
      "        [54., 96.]], grad_fn=<MulBackward0>)\n",
      "-------------------\n",
      "COMPUTE GRADIENT-2\n",
      "-------------------\n",
      "AUTOGRAD:\n",
      " tensor([[ -2.4969, -22.9838],\n",
      "        [-44.7827, -66.5180]])\n",
      "EXPECTED:\n",
      " tensor([[ -2.4969, -22.9838],\n",
      "        [-44.7827, -66.5180]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"COMPUTE GRADIENT-1\")\n",
    "print(\"-------------------\")\n",
    "x = torch.tensor(\n",
    "    [[1.,2.], [3., 4.]],\n",
    "    requires_grad=True)\n",
    "# FORWARD \n",
    "y \t= (2*x**3).sum();\n",
    "# BACKWARD\n",
    "y.backward(); \n",
    "print(\"AUTOGRAD:\\n\",x.grad); \n",
    "print(\"EXPECTED:\\n\",6*x**2)\n",
    "\n",
    "print(\"-------------------\")\n",
    "print(\"COMPUTE GRADIENT-2\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "x = torch.tensor([[1.,2.], [3., 4.]],\n",
    "    requires_grad=True)\n",
    "y = x**3; \t #FORWARD\n",
    "y = 2*y; \n",
    "y = y.sin() \n",
    "y = y.sum() \n",
    "y.backward() #BACKWARD\n",
    "print(\"AUTOGRAD:\\n\",x.grad); \n",
    "print(\"EXPECTED:\\n\",torch.cos(2*x**3)*6*x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY590')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b6082c1c9eef3a910163f232074f2e179e34ed8469dd2c24c723d1290ad549e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
