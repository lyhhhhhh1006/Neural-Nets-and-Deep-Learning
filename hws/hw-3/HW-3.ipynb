{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW-3: \n",
    "\n",
    "Author: J. Hickman\n",
    "\n",
    "**Overview:**\n",
    "* In deep learning we don't always have to train our neural networks from scratch\n",
    "* Often \"pre-trained models\" exist which we can \"pull of the shelf\" and use as part of a data processing pipeline. \n",
    "* In this assignment, we will use the popular \"You only look once\" (YOLO) deep learning algorithm to do object detection.\n",
    "  * https://pytorch.org/hub/ultralytics_yolov5/\n",
    "* Assume you are working for a company interested in traffic patterns and driver behavior \n",
    "  * For example, a car-insurance company, a traffic data analytics firm, or a self driving car start-up \n",
    "* This company has \"dash-camera\" footage from various cars in their \"fleet\" \n",
    "* As an initial proof of concept they want you to write a code to track the locations of other vehicles from the recordings \n",
    "* They also want you to analyze the time-dependence of traffic patterns found in the videos.\n",
    "\n",
    "**Submission:**\n",
    "* You need to upload ONE document to Canvas when you are done\n",
    "  * (1) A PDF (or HTML) of the completed form of the \"HW-3.ipynb\" document \n",
    "* The final uploaded version should NOT have any code-errors present \n",
    "* All outputs must be visible in the uploaded version, including code-cell outputs, images, graphs, etc\n",
    "* **Total points:** 41.66\n",
    "\n",
    "**Note**:\n",
    "* There are many ways to do this assignment and the methods below are guidelines not rules.\n",
    "* If you find more efficient ways to complete the objectives then feel free to do it however you want. \n",
    "* **IMPORTANT: START SMALL THEN SCALE UP** \n",
    "  * Get everything working for a simple case with a few images, once everything seems to be working correctly then run it on the entire data set\n",
    "\n",
    "**Data source**:\n",
    "* Dash cam footage: https://www.youtube.com/watch?v=9qy4lExIetk\n",
    "* Website to download youtube videos: https://en.y2mate.is/67/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihuiliu_/opt/anaconda3/envs/anly590/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil \n",
    "import os\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-3.0 \n",
    "\n",
    "Open the file \"video-res-2.mp4\" and watch a few minutes to get familiar with the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-3.1: Pre-processing\n",
    "\n",
    "* The video is 2hr8min55s which is 2*60*60+8*60+55=7735 seconds \n",
    "* The frame rate for the video is roughly 30 frames per second \n",
    "* So there are around 7735*30=232050 frames\n",
    "* Write code to read and convert the video \"video-res-2.mp4\" into an ORDERED set of images \n",
    "* Include a parameter to save frames every N seconds \n",
    "* Don't save every frame, at first save frames every 50 seconds, that will be around 155 images\n",
    "* Once everything is working, save frames every 10 seconds and re-run the code for the final product.\n",
    "* Save the images to a folder \"frames\" with the convention \n",
    "  * \"frames/00010.jpg\" for the frame 10 seconds into the video\n",
    "  * \"frames/00020.jpg\" for the frame 20 seconds into the video and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m vidcap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo-res-2.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('video-res-2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "moving_ave = np.convolve(video-res-2, np.ones(N)/N, mode = 'same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-3.2: Explore the model \n",
    "\n",
    "Before processing the video data, we want to make sure we can get YOLO working correctly for a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT CODE TO LOAD THE YOLO MODEL USING PYTORCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AT FIRST USE THE FOLLOWING IMAGES AS A TEST CASE\n",
    "images=['frames/00050.jpg','frames/00200.jpg']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO EVALUATE THE YOLO MODEL ON THESE IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHEN WORKING IN PYTHON WITH AN OBJECT OF AN UN-FAMILIAR CLASS IT IS \n",
    "# VERY USEFUL TO FIGURE OUT THE CLASSES ATTRIBUTES AND METHOD\n",
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO FIGURE OUT WHAT THE OBJECTS ATTRIBUTES OF THE \"results\" OBJECT ARE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  INSERT CODE TO FIGURE OUT WHAT THE OBJECTS METHODS OF THE \"results\" OBJECT ARE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT A SUMMARY OF THE RESULT\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE INFORMATION ABOUT THE BOUNDING BOXES CAN BE EXTRACTED AS FOLLOWS\n",
    "print(results.pandas().xyxy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO REMOVE THE FOLDER \"runs\" IF IT EXISTS THEN RUN \"results.save()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT THE FIRST IMAGE\n",
    "Image(\"runs/detect/exp/00050.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"runs/detect/exp/00200.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part-3.3: Explore the results  \n",
    "\n",
    "The following code will plot the image and add a verticle line roughly down the center of the car's hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(results.imgs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT IMAGE WITH REGIONAL SUB-DIVIDING LINES\n",
    "def plot_lines(img):\n",
    "    YMAX=img.shape[0]\n",
    "    XMAX=img.shape[1]\n",
    "    XCENTER=0.57*XMAX\n",
    "\n",
    "    x1 = XCENTER; y1 = 0; x2 = XCENTER; y2 = YMAX \n",
    "    plt.plot([x1,x2], [y1,y2], marker = 'o',color=\"red\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "results.print()\n",
    "plot_lines(results.imgs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO MODIFY THE FUNCTION TO GENERATE THE FOLLOWING IMAGE TO ROUGHLY ISOLATE THE LANE\n",
    "# YOU CAN JUST USE GEOMETRY TO DO THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert a function to output a modified version of the results.pandas().xyxy[i] data-frame in the following ways \n",
    "\n",
    "* normalize (scale) the xmin, xmax by the width of the image and ymin, ymax by the height --> HxW=1x1 \n",
    "* compute the area and center of each box using the normalized coordinates\n",
    "* add a column named \"nearby\" which is True if normalized_area>0.05\n",
    "* **Optional**: Use The geometric lane construction from the previous image and the location of the box center to compute which lane (left,center,right) nearby vehicles are in\n",
    " \n",
    "```\n",
    "       xmin      ymin      xmax      ymax  confidence  ...   name nearby  \\\n",
    "0  0.677506  0.515625  0.771468  0.680202    0.859959  ...  truck  False   \n",
    "1  0.831234  0.617149  0.977826  0.743249    0.851794  ...    car  False   \n",
    "2  0.002621  0.457946  0.410202  0.926958    0.820941  ...  truck   True   \n",
    "3  0.547734  0.598833  0.656238  0.750011    0.581989  ...    car  False   \n",
    "4  0.473275  0.594087  0.518594  0.662508    0.503990  ...    car  False   \n",
    "\n",
    "       area  x_center  y_center  \n",
    "0  0.015464  0.724487  0.597913  \n",
    "1  0.018485  0.904530  0.680199  \n",
    "2  0.191160  0.206412  0.692452  \n",
    "3  0.016403  0.601986  0.674422  \n",
    "4  0.003101  0.495935  0.628297  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT CODE TO MODIFY THE DATAFRAME \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3.4: Process all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO FORM AN ORDERED (SORTED) LIST OF ALL IMAGES IN \"frames\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO RUN YOLO ON THE COMPLETE LIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-3.5: Time-series analysis \n",
    "\n",
    "Loop over the results and build arrays with time-series data for the following \n",
    "* The frames should be ordered so you can treat the index as a \"time\" variables\n",
    "* Total number num_cars and num_trucks in each frame\n",
    "* num_neighbor = Number of neighboring cars and trucks (use normalized box area > .05 to signify a nearby car or truck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5.1: INSERT CODE TO LOOP OVER RESULTS AND BUILD ARRAYS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO GENERATE THE FOLLOWING PLOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE TO GENERATE THE FOLLOWING PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Dynamic analysis (more advanced)\n",
    "\n",
    "* Save more frames and see if you can write a script to track near-by neighboring cars from one frame to the next\n",
    "  * Using this information, compute some measure of relative velocity of passing cars \n",
    "  * Plot this average velocity as a time series and discuss the meaning\n",
    "* Research the mathematics of \"perspective\" and see if you can encode the math to predict an estimate for the distance to neighboring vehicles from the area of the box\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b6082c1c9eef3a910163f232074f2e179e34ed8469dd2c24c723d1290ad549e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
